{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Correct path formatting (use a raw string or replace \\ with /)\n",
    "folder_path = r'C:\\Users\\skhadijah\\Downloads\\FAH\\ANALYSIS'\n",
    "# Alternatively: folder_path = 'C:/Users/skhadijah/Downloads/FAH/ANALYSIS'\n",
    "\n",
    "data_frames = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith('.xlsx'):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        try:\n",
    "            df = pd.read_excel(file_path)\n",
    "            data_frames.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to read {file_path}: {e}\")\n",
    "\n",
    "# Concatenate all data frames into one, handling potential issues with non-aligned columns\n",
    "merged_df = pd.concat(data_frames, ignore_index=True, sort=False)\n",
    "\n",
    "# List of columns you're interested in\n",
    "selected_columns = [\n",
    "    'Accounting Date', 'Accounting Event', 'Accounting Class','Enter Currency', 'Entered DR', 'Entered CR',\n",
    "    'Accounted DR', 'Accounted CR', 'Source Accounting Event',\n",
    "    'Accounting Line Type', 'Customer Number', 'Customer Account Number', 'Transaction Number',\n",
    "    'Credit Debit Indicator', 'Posting Date'\n",
    "]\n",
    "\n",
    "\n",
    "# Assuming 'cust' is your DataFrame\n",
    "gl = merged_df[selected_columns]\n",
    "\n",
    "#Save file\n",
    "gl.to_csv('C:/Users/skhadijah/Downloads/full_gl.csv', index=False)\n",
    "\n",
    "gl.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gl.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate for daily\n",
    "\n",
    "# Ensure the 'Accounting Date' is a datetime type\n",
    "gl['Accounting Date'] = pd.to_datetime(gl['Accounting Date'])\n",
    "\n",
    "#Filter all the data to select \"Accounting Line Type\" for CUSTOMER_CMSA and CUSTOMER_CMSA_SAVINGS_POT\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Add a column for debit (money out) and credit (money in) counts\n",
    "# Assign 1 to every transaction for counting purposes\n",
    "gl['Debit_Count'] = (gl['Entered DR'] > 0).astype(int)\n",
    "gl['Credit_Count'] = (gl['Entered CR'] > 0).astype(int)\n",
    "\n",
    "# Group by 'Customer Account Number' and 'Accounting Date' (daily as an example)\n",
    "grouped = gl.groupby(['Customer Account Number', pd.Grouper(key='Accounting Date', freq='D')])\n",
    "\n",
    "# Aggregate transactions\n",
    "daily_aggregated_transactions = grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate daily balance for each customer account (cumulative credits - cumulative debits)\n",
    "daily_aggregated_transactions['balance'] = daily_aggregated_transactions.groupby(level=0).cumsum().eval('amount_credit - amount_debit')\n",
    "\n",
    "# Reset index for daily aggregated transactions\n",
    "daily_aggregated_transactions = daily_aggregated_transactions.reset_index()\n",
    "\n",
    "#Save file\n",
    "daily_aggregated_transactions.to_csv('C:/Users/skhadijah/Downloads/customer_trend/daily_agg.csv', index=False)\n",
    "\n",
    "# Display the first few rows to check\n",
    "daily_aggregated_transactions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Aggregate Weekly\n",
    "\n",
    "# Group by 'Customer Account Number' and 'Accounting Date' (weekly)\n",
    "weekly_grouped = gl.groupby(['Customer Account Number', pd.Grouper(key='Accounting Date', freq='W')])\n",
    "\n",
    "#Filter all the data to select \"Accounting Line Type\" for CUSTOMER_CMSA and CUSTOMER_CMSA_SAVINGS_POT\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Aggregate transactions for weekly data\n",
    "weekly_aggregated_transactions = weekly_grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate weekly balance for each customer account (cumulative credits - cumulative debits)\n",
    "weekly_aggregated_transactions['balance'] = weekly_aggregated_transactions.groupby(level=0).cumsum().eval('amount_credit - amount_debit')\n",
    "\n",
    "# Reset index for daily aggregated transactions\n",
    "weekly_aggregated_transactions = weekly_aggregated_transactions.reset_index()\n",
    "\n",
    "#Save file\n",
    "weekly_aggregated_transactions.to_csv('C:/Users/skhadijah/Downloads/customer_trend/weekly_agg.csv', index=False)\n",
    "\n",
    "# Display the first few rows to check weekly data\n",
    "weekly_aggregated_transactions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Monthly Aggregation\n",
    "\n",
    "# Group by 'Customer Account Number' and 'Accounting Date' (monthly)\n",
    "monthly_grouped = gl.groupby(['Customer Account Number', pd.Grouper(key='Accounting Date', freq='M')])\n",
    "\n",
    "#Filter all the data to select \"Accounting Line Type\" for CUSTOMER_CMSA and CUSTOMER_CMSA_SAVINGS_POT\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Aggregate transactions for monthly data\n",
    "monthly_aggregated_transactions = monthly_grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate monthly balance for each customer account (cumulative credits - cumulative debits)\n",
    "monthly_aggregated_transactions['Net Flow'] = monthly_aggregated_transactions.groupby(level=0).cumsum().eval('amount_credit - amount_debit')\n",
    "\n",
    "# Reset index for daily aggregated transactions\n",
    "monthly_aggregated_transactions = monthly_aggregated_transactions.reset_index()\n",
    "\n",
    "#Save file\n",
    "monthly_aggregated_transactions.to_csv('C:/Users/skhadijah/Downloads/customer_trend/monthly_agg.csv', index=False)\n",
    "\n",
    "# Display the first few rows to check monthly data\n",
    "monthly_aggregated_transactions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "# Assuming 'gl' is your DataFrame containing transaction data\n",
    "\n",
    "# Step 1: Prepare the DataFrame\n",
    "gl['Accounting Date'] = pd.to_datetime(gl['Accounting Date'])\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "gl['Debit_Count'] = (gl['Entered DR'] > 0).astype(int)\n",
    "gl['Credit_Count'] = (gl['Entered CR'] > 0).astype(int)\n",
    "# gl = gl[gl['Accounting Date'] >= pd.Timestamp('2022-12-01')]\n",
    "# gl = gl[gl['Accounting Date'] <= pd.Timestamp('2024-03-31')]\n",
    "# gl = gl[(gl['Accounting Date'] >= pd.Timestamp('2022-01-01')) & (gl['Accounting Date'] <= pd.Timestamp('2024-03-31'))]\n",
    "\n",
    "\n",
    "# Aggregate daily transactions\n",
    "grouped = gl.groupby(['Customer Account Number', pd.Grouper(key='Accounting Date', freq='D')])\n",
    "daily_aggregated_transactions = grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate daily balance\n",
    "daily_aggregated_transactions['balance'] = daily_aggregated_transactions.groupby(level=0).cumsum().eval('amount_credit - amount_debit')\n",
    "\n",
    "# Step 2: Calculate RFM Metrics\n",
    "now = datetime.now()  # Consider using a specific reference date for analysis consistency\n",
    "gl['Net Amount'] = gl['Entered CR'] - gl['Entered DR']\n",
    "rfm = gl.groupby('Customer Account Number').agg(\n",
    "    Recency=('Accounting Date', lambda x: (now - x.max()).days),\n",
    "    Frequency=('Customer Account Number', 'count'),\n",
    "    Monetary=('Net Amount', 'sum')\n",
    ")\n",
    "\n",
    "# Step 3: Score and Segment (with duplicate bin edge handling)\n",
    "quantiles = rfm.quantile(q=[0.25, 0.5, 0.75]).to_dict()\n",
    "\n",
    "# Ensure bins are unique by adjusting them slightly if duplicates are found\n",
    "bins_recency = sorted(set([-np.inf, quantiles['Recency'][0.25], quantiles['Recency'][0.5], quantiles['Recency'][0.75], np.inf]))\n",
    "bins_frequency = sorted(set([-np.inf, quantiles['Frequency'][0.25], quantiles['Frequency'][0.5], quantiles['Frequency'][0.75], np.inf]))\n",
    "bins_monetary = sorted(set([-np.inf, quantiles['Monetary'][0.25], quantiles['Monetary'][0.5], quantiles['Monetary'][0.75], np.inf]))\n",
    "\n",
    "# Apply scoring, adjusting label counts based on the number of unique bins\n",
    "rfm['R_Score'] = pd.cut(rfm['Recency'], bins=bins_recency, labels=range(len(bins_recency)-1, 0, -1), right=False)\n",
    "rfm['F_Score'] = pd.cut(rfm['Frequency'], bins=bins_frequency, labels=range(1, len(bins_frequency)), right=False)\n",
    "rfm['M_Score'] = pd.cut(rfm['Monetary'], bins=bins_monetary, labels=range(1, len(bins_monetary)), right=False)\n",
    "\n",
    "def assign_segment(row):\n",
    "    if row['R_Score'] > 2 and row['F_Score'] > 2:\n",
    "        return 'Loyal Customers'\n",
    "    elif row['R_Score'] > 2 and row['F_Score'] <= 2:\n",
    "        return 'Potential Loyalist'\n",
    "    elif row['R_Score'] > 2 and row['F_Score'] == 1:\n",
    "        return 'Recent Users'\n",
    "    elif row['R_Score'] == 1 and row['F_Score'] > 2:\n",
    "        return 'Needs Attention'\n",
    "    elif row['R_Score'] == 1 and row['F_Score'] <= 2:\n",
    "        return 'About To Sleep'\n",
    "    elif row['M_Score'] == 1:\n",
    "        return 'Price Sensitive'\n",
    "    elif row['F_Score'] == 1 and row['M_Score'] > 2:\n",
    "        return \"Can't Lose Them\"\n",
    "    elif row['R_Score'] == 1 and row['F_Score'] == 1:\n",
    "        return 'Hibernating'\n",
    "    else:\n",
    "        return 'Promising'\n",
    "    \n",
    "\n",
    "# # Scoring the RFM metrics\n",
    "# rfm['F_Score'] = pd.qcut(rfm['Frequency'], 5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "# rfm['M_Score'] = pd.qcut(rfm['Monetary'], 5, labels=[1, 2, 3, 4, 5], duplicates='drop')\n",
    "# rfm['R_Score'] = pd.qcut(rfm['Recency'].rank(method='first'), 5, labels=[5, 4, 3, 2, 1])\n",
    "\n",
    "# def assign_segment(row):\n",
    "#     # Convert quintile labels to integers for comparison\n",
    "#     F_Score = int(row['F_Score'])\n",
    "#     R_Score = int(row['R_Score'])\n",
    "#     M_Score = int(row['M_Score'])\n",
    "\n",
    "#     if F_Score == 5 and R_Score >= 2 and M_Score == 5:\n",
    "#         return 'Loyal Customers (Champions)'\n",
    "#     elif F_Score >= 3 and R_Score >= 2 and M_Score >= 3:\n",
    "#         return 'Emerging Loyalists (Potential Loyalist)'\n",
    "#     elif R_Score == 5 and F_Score <= 3 and M_Score in [2, 3]:\n",
    "#         return 'New Enthusiasts (Recent Users)'\n",
    "#     elif R_Score >= 2 and F_Score <= 3 and M_Score == 2:\n",
    "#         return 'Inconsistent Savers (Promising)'\n",
    "#     elif R_Score == 1 and F_Score in [3, 4] and M_Score in [2, 3]:\n",
    "#         return 'Casual Bankers (Needs Attention)'\n",
    "#     elif R_Score == 1 and F_Score <= 2 and M_Score == 5:\n",
    "#         return 'Slipping Away (Can\\'t Lose Them)'\n",
    "#     elif R_Score <= 2 and F_Score <= 2 and M_Score <= 2:\n",
    "#         return 'Hibernating'\n",
    "#     elif F_Score in [1, 2] and R_Score in [1, 2] and M_Score in [1, 2]:\n",
    "#         return 'About To Sleep'\n",
    "#     elif F_Score in [1, 2] and M_Score in [1, 2]:\n",
    "#         return 'Price Sensitive'\n",
    "#     elif R_Score == 1 and F_Score == 1 and M_Score == 1:\n",
    "#         return 'Lost'\n",
    "#     else:\n",
    "#         return 'Other'\n",
    "\n",
    "# Apply the function to the RFM dataframe\n",
    "rfm['Segment'] = rfm.apply(assign_segment, axis=1)\n",
    "\n",
    "# Reset index for daily aggregated transactions\n",
    "rfm = rfm.reset_index()\n",
    "\n",
    "#Save file\n",
    "rfm.to_csv('C:/Users/skhadijah/Downloads/customer_trend/rfm.csv', index=False)\n",
    "\n",
    "# Display the results\n",
    "rfm.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge customer data and RFM\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the customer data\n",
    "file_path = 'C:/Users/skhadijah/Downloads/Customer-Ultimate-Balance-V2-20052024.csv'\n",
    "cust_df = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Select the variables you want to keep\n",
    "selected_columns = [\n",
    "    'customerId', 'tm_account_id', 'account_accountNumber', 'createdOn_x_x',\n",
    "    'lastUpdate', 'overallStatus', 'fullname', 'age', 'placeOfBirth', 'gender',\n",
    "    'nationality', 'type', 'device_os', 'device_versioning', 'device_model',\n",
    "    'ledger_balance', 'balance_created_balance_denomination', 'total_credit',\n",
    "    'total_debit', 'last_transaction_date', 'device_status',\n",
    "    'preferences_pushNotificationsAllowed', 'preferences_marketingEmailFlag',\n",
    "    'preferences_marketingPhoneCallFlag', 'preferences_marketingSmsFlag',\n",
    "    'preferences_marketingPushFlag', 'account_status', 'offboardingStatus_string',\n",
    "    'ftv_otherSideFullName', 'ftv_otherSideBankCode', 'verificationStatus',\n",
    "    'status', 'number', 'openingTimestamp', 'activationTimestamp', 'employer',\n",
    "    'employmentType', 'employmentSector', 'occupation', 'annualIncomeBracket',\n",
    "    'residential_address_line1', 'residential_address_line2', 'residential_address_line3',\n",
    "    'residential_address_line4', 'residential_address_line5', 'residential_address_country_code',\n",
    "    'residential_address_city', 'residential_address_postal_code', 'residential_address_subdivision',\n",
    "    'residential_address_subdivision_code', 'residential_address_type', 'mailing_address_line1',\n",
    "    'mailing_address_line2', 'mailing_address_line3', 'mailing_address_line4', 'mailing_address_line5',\n",
    "    'mailing_address_country_code', 'mailing_address_city', 'mailing_address_postal_code',\n",
    "    'mailing_address_subdivision', 'mailing_address_subdivision_code', 'mailing_address_type',\n",
    "    'mailing_address_createdOn', 'mailing_address_lastUpdated', 'mailing_address_smeId', 'maritalStatus',\n",
    "    'ethnicity', 'Bumi', 'residencyStatus', 'entityType', 'accountSettingUpReasons_0',\n",
    "    'accountSettingUpReasons_1', 'accountSettingUpReasons_2', 'accountSettingUpReasons_3', 'crr_score',\n",
    "    'crr_rating', 'crr_timestamp', 'nameScreeningMatch', 'matchStatus', 'totalHits', 'totalBlacklistHits',\n",
    "    'complyAdv_timestamp'\n",
    "]\n",
    "\n",
    "# Ensure that the column exists before selecting to avoid KeyError\n",
    "cust_selected = cust_df[selected_columns]\n",
    "\n",
    "# Merge the selected customer data with the RFM dataframe on the account number\n",
    "# Assuming the RFM dataframe is named 'rfm' and the common identifier column is 'account_accountNumber' in 'cust_selected' and 'Customer Account Number' in 'rfm'\n",
    "merge_df = pd.merge(rfm, cust_selected,  how='inner', left_on='Customer Account Number', right_on='account_accountNumber')\n",
    "\n",
    "# Modify the 'ethnicity' and 'maritalStatus' columns based on the given mappings\n",
    "merge_df['ethnicity'] = merge_df['ethnicity'].replace({'Cina': 'Chinese', 'Melayu': 'Malay'})\n",
    "merge_df['maritalStatus'] = merge_df['maritalStatus'].replace({'Bujang': 'Single', 'Berkahwin': 'Married'})\n",
    "\n",
    "#Save file\n",
    "merge_df.to_csv('C:/Users/skhadijah/Downloads/customer_trend/rfm_cust.csv', index=False)\n",
    "\n",
    "# Show the first few rows of the merged dataframe\n",
    "merge_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Assuming 'rfm' is your DataFrame and it's already loaded with 'Recency', 'Frequency', 'Monetary' columns\n",
    "\n",
    "# Function to add a normal distribution curve to histograms\n",
    "def add_normal_curve(fig, data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    min_val, max_val = np.min(data), np.max(data)\n",
    "    x = np.linspace(min_val, max_val, num=300)\n",
    "    y = stats.norm.pdf(x, mean, std)\n",
    "    y = y / max(y) * data.value_counts().max()  # Normalize to the height of the histogram\n",
    "    fig.add_trace(go.Scatter(x=x, y=y, mode='lines', name='Normal fit', line=dict(color='black', width=2)))\n",
    "\n",
    "# Plot for Recency\n",
    "fig_recency = px.histogram(rfm, x='Recency',\n",
    "                           title='Distribution of Recency',\n",
    "                           labels={'Recency': 'Days since last transaction'},\n",
    "                           nbins=50, \n",
    "                           color_discrete_sequence=['#636EFA'])\n",
    "add_normal_curve(fig_recency, rfm['Recency'])\n",
    "fig_recency.show()\n",
    "\n",
    "# Plot for Frequency\n",
    "fig_frequency = px.histogram(rfm, x='Frequency',\n",
    "                             title='Distribution of Frequency',\n",
    "                             labels={'Frequency': 'Number of transactions'},\n",
    "                             nbins=50, \n",
    "                             color_discrete_sequence=['#EF553B'])\n",
    "add_normal_curve(fig_frequency, rfm['Frequency'])\n",
    "fig_frequency.show()\n",
    "\n",
    "# Plot for Monetary\n",
    "fig_monetary = px.histogram(rfm, x='Monetary',\n",
    "                            title='Distribution of Monetary Value',\n",
    "                            labels={'Monetary': 'Total spent'},\n",
    "                            nbins=50, \n",
    "                            color_discrete_sequence=['#00CC96'])\n",
    "add_normal_curve(fig_monetary, rfm['Monetary'])\n",
    "fig_monetary.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Month on Month Balance\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Convert 'Accounting Date' to datetime format\n",
    "gl['Accounting Date'] = pd.to_datetime(gl['Accounting Date'])\n",
    "\n",
    "# Filter to include only relevant 'Accounting Line Type'\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Create count columns for debits and credits\n",
    "gl['Debit_Count'] = (gl['Entered DR'] > 0).astype(int)\n",
    "gl['Credit_Count'] = (gl['Entered CR'] > 0).astype(int)\n",
    "\n",
    "# Group by 'Customer Account Number' and 'Accounting Date' with a monthly frequency\n",
    "grouped = gl.groupby(['Customer Account Number', pd.Grouper(key='Accounting Date', freq='M')])\n",
    "\n",
    "# Aggregate transactions monthly\n",
    "monthly_aggregated_transactions = grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "# Calculate monthly balance for each customer account\n",
    "monthly_aggregated_transactions['balance'] = monthly_aggregated_transactions['amount_credit'] - monthly_aggregated_transactions['amount_debit']\n",
    "\n",
    "# Calculate month-on-month change\n",
    "monthly_aggregated_transactions['mom_change'] = monthly_aggregated_transactions.groupby(level=0)['balance'].diff().fillna(0)\n",
    "\n",
    "# Reset index\n",
    "monthly_aggregated_transactions.reset_index(inplace=True)\n",
    "\n",
    "# File path to save the CSV file\n",
    "output_file_path = 'C:/Users/skhadijah/Downloads/customer_trend/monthly_balance_change.csv'\n",
    "monthly_aggregated_transactions.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"File has been saved to:\", output_file_path)\n",
    "# Display the first few rows to check the output\n",
    "monthly_aggregated_transactions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Assume `gl` is already prepared with the relevant data loaded as shown in the previous examples.\n",
    "\n",
    "# Convert 'Accounting Date' to datetime format\n",
    "gl['Accounting Date'] = pd.to_datetime(gl['Accounting Date'])\n",
    "\n",
    "# Filter to include only relevant 'Accounting Line Type'\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Create count columns for debits and credits\n",
    "gl['Debit_Count'] = (gl['Entered DR'] > 0).astype(int)\n",
    "gl['Credit_Count'] = (gl['Entered CR'] > 0).astype(int)\n",
    "\n",
    "# Group by 'Accounting Date' with a monthly frequency\n",
    "grouped = gl.groupby(pd.Grouper(key='Accounting Date', freq='M'))\n",
    "\n",
    "# Aggregate transactions monthly\n",
    "monthly_aggregated_transactions = grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate monthly balance for the bank\n",
    "monthly_aggregated_transactions['balance'] = monthly_aggregated_transactions['amount_credit'] - monthly_aggregated_transactions['amount_debit']\n",
    "\n",
    "# Calculate month-on-month change\n",
    "monthly_aggregated_transactions['mom_change'] = monthly_aggregated_transactions['balance'].diff().fillna(0)\n",
    "\n",
    "# Reset index to get 'Accounting Date' as a column\n",
    "monthly_aggregated_transactions.reset_index(inplace=True)\n",
    "\n",
    "# File path to save the CSV file\n",
    "output_file_path = 'C:/Users/skhadijah/Downloads/customer_trend/monthly_balance_change_bankwide.csv'\n",
    "monthly_aggregated_transactions.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"File has been saved to:\", output_file_path)\n",
    "# Display the first few rows to check the output\n",
    "monthly_aggregated_transactions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import os\n",
    "\n",
    "# Assuming `gl` DataFrame is already prepared with the relevant data loaded.\n",
    "\n",
    "# Convert 'Accounting Date' to datetime format\n",
    "gl['Accounting Date'] = pd.to_datetime(gl['Accounting Date'])\n",
    "\n",
    "# Filter to include only relevant 'Accounting Line Type'\n",
    "gl = gl[gl['Accounting Line Type'].isin(['CUSTOMER_CMSA', 'CUSTOMER_CMSA_SAVINGS_POT'])]\n",
    "\n",
    "# Adjust the 'Accounting Date' to start from 18th of each month\n",
    "# Subtract days to set all dates to the previous month if before the 18th\n",
    "gl['Adjusted Date'] = gl['Accounting Date'].apply(lambda x: x - pd.DateOffset(days=x.day-18) if x.day >= 18 else x - pd.DateOffset(months=1, days=x.day-18))\n",
    "\n",
    "# Create count columns for debits and credits\n",
    "gl['Debit_Count'] = (gl['Entered DR'] > 0).astype(int)\n",
    "gl['Credit_Count'] = (gl['Entered CR'] > 0).astype(int)\n",
    "\n",
    "# Group by 'Adjusted Date' with a monthly frequency starting from 18th\n",
    "grouped = gl.groupby(pd.Grouper(key='Adjusted Date', freq='M'))\n",
    "\n",
    "# Aggregate transactions monthly\n",
    "monthly_aggregated_transactions = grouped.agg(\n",
    "    count_debit=pd.NamedAgg(column='Debit_Count', aggfunc='sum'),\n",
    "    amount_debit=pd.NamedAgg(column='Entered DR', aggfunc='sum'),\n",
    "    count_credit=pd.NamedAgg(column='Credit_Count', aggfunc='sum'),\n",
    "    amount_credit=pd.NamedAgg(column='Entered CR', aggfunc='sum')\n",
    ")\n",
    "\n",
    "# Calculate monthly balance for the bank\n",
    "monthly_aggregated_transactions['balance'] = monthly_aggregated_transactions['amount_credit'] - monthly_aggregated_transactions['amount_debit']\n",
    "\n",
    "# Calculate month-on-month change\n",
    "monthly_aggregated_transactions['mom_change'] = monthly_aggregated_transactions['balance'].diff().fillna(0)\n",
    "\n",
    "# Reset index to get 'Adjusted Date' as a column\n",
    "monthly_aggregated_transactions.reset_index(inplace=True)\n",
    "\n",
    "# File path to save the CSV file\n",
    "output_file_path = 'C:/Users/skhadijah/Downloads/customer_trend/monthly_balance_change_bankwide-18th.csv'\n",
    "monthly_aggregated_transactions.to_csv(output_file_path, index=False)\n",
    "\n",
    "print(\"File has been saved to:\", output_file_path)\n",
    "# Display the first few rows to check the output\n",
    "print(monthly_aggregated_transactions.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

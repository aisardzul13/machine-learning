{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define base directory\n",
    "# # base_dir = r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\TEMP'\n",
    "# base_dir = r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q13.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q13.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q13.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q13.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q13.xlsx\n",
      "\n",
      "September Q13 Data Preview:\n",
      "Shape: (41928, 3)\n",
      "   Response ID    Brand  Aware Y/N\n",
      "0          217  Samsung          0\n",
      "1          219  Samsung          0\n",
      "\n",
      "October Q13 Data Preview:\n",
      "Shape: (43164, 3)\n",
      "   Response ID    Brand  Aware Y/N\n",
      "0        16909  Samsung          1\n",
      "1        16910  Samsung          0\n",
      "\n",
      "November Q13 Data Preview:\n",
      "Shape: (43476, 3)\n",
      "   Response ID    Brand  Aware Y/N\n",
      "0        48910  Samsung          0\n",
      "1        48926  Samsung          1\n",
      "\n",
      "December Q13 Data Preview:\n",
      "Shape: (42612, 3)\n",
      "   Response ID    Brand  Aware Y/N\n",
      "0        78293  Samsung          1\n",
      "1        78361  Samsung          1\n",
      "\n",
      "January Q13 Data Preview:\n",
      "Shape: (43176, 3)\n",
      "   Response ID    Brand  Aware Y/N\n",
      "0        96112  Samsung          0\n",
      "1        96145  Samsung          1\n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(year_folder, subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, year_folder, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# # Load the datasets\n",
    "# sept13 = load_excel_file('2024', 'SEPTEMBER', 'combined_q13.xlsx')\n",
    "# oct13  = load_excel_file('2024', 'OCTOBER',  'combined_q13.xlsx')\n",
    "# nov13  = load_excel_file('2024', 'NOVEMBER', 'combined_q13.xlsx')\n",
    "# dec13  = load_excel_file('2024', 'DECEMBER', 'combined_q13.xlsx')\n",
    "# jan13  = load_excel_file('2025', 'JANUARY',  'combined_q13.xlsx')\n",
    "# feb13  = load_excel_file('2025', 'FEBRUARY', 'combined_q13.xlsx')\n",
    "\n",
    "# # Preview the first few rows and shape of each dataset\n",
    "# def preview_dataset(df, name):\n",
    "#     if df is not None:\n",
    "#         print(f\"\\n{name} Q13 Data Preview:\")\n",
    "#         print(f\"Shape: {df.shape}\")  # (rows, columns)\n",
    "#         print(df.head(2))\n",
    "\n",
    "# preview_dataset(sept13, \"September\")\n",
    "# preview_dataset(oct13,  \"October\")\n",
    "# preview_dataset(nov13,  \"November\")\n",
    "# preview_dataset(dec13,  \"December\")\n",
    "# preview_dataset(jan13,  \"January\")\n",
    "# preview_dataset(feb13,  \"February\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q14.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q14.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q14.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q14.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q14.xlsx\n",
      "\n",
      "September Q14 Data Preview:\n",
      "Shape: (503136, 5)\n",
      "   Response ID                                             Source  \\\n",
      "0          217  Not seen/heard:DYSON:AU - Where have you seen,...   \n",
      "1          217  Not seen/heard:SMEG:AU - Where have you seen, ...   \n",
      "\n",
      "   cleaned_source  Brand_awareness  Brand  \n",
      "0  Not seen/heard                0  DYSON  \n",
      "1  Not seen/heard               99   SMEG  \n",
      "\n",
      "October Q14 Data Preview:\n",
      "Shape: (517568, 5)\n",
      "   Response ID                                             Source  \\\n",
      "0        16909  Somewhere else:HAIER:AU - Where have you seen,...   \n",
      "1        16909  At Events (fairs & exhibitions, sports, cookin...   \n",
      "\n",
      "                                      cleaned_source  Brand_awareness  Brand  \n",
      "0                                     Somewhere else                0  HAIER  \n",
      "1  At Events (fairs & exhibitions, sports, cookin...                0  MIELE  \n",
      "\n",
      "November Q14 Data Preview:\n",
      "Shape: (521312, 5)\n",
      "   Response ID                                             Source  \\\n",
      "0        48910  Newspaper/Magazine (advertisements):SMEG:AU - ...   \n",
      "1        48910  On TV (live, catch up or on demand):SMEG:AU - ...   \n",
      "\n",
      "                        cleaned_source  Brand_awareness Brand  \n",
      "0  Newspaper/Magazine (advertisements)                0  SMEG  \n",
      "1  On TV (live, catch up or on demand)                0  SMEG  \n",
      "\n",
      "December Q14 Data Preview:\n",
      "Shape: (516096, 5)\n",
      "   Response ID                                             Source  \\\n",
      "0        78230  At Events (fairs & exhibitions, sports, cookin...   \n",
      "1        78230  When searching or shopping online:SAMSUNG:GM -...   \n",
      "\n",
      "                                      cleaned_source  Brand_awareness    Brand  \n",
      "0  At Events (fairs & exhibitions, sports, cookin...                0       LG  \n",
      "1                  When searching or shopping online                0  SAMSUNG  \n",
      "\n",
      "January Q14 Data Preview:\n",
      "Shape: (518112, 5)\n",
      "   Response ID                                             Source  \\\n",
      "0          219  In a store:NEFF:UK - Where have you seen, hear...   \n",
      "1          219  Not seen/heard:BOSCH:UK - Where have you seen,...   \n",
      "\n",
      "   cleaned_source  Brand_awareness  Brand  \n",
      "0      In a store                0   NEFF  \n",
      "1  Not seen/heard                0  BOSCH  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# # Load the datasets\n",
    "# sept14 = load_excel_file('SEPTEMBER', 'vcombined_q14.xlsx')\n",
    "# oct14  = load_excel_file('OCTOBER',  'combined_q14.xlsx')\n",
    "# nov14  = load_excel_file('NOVEMBER', 'combined_q14.xlsx')\n",
    "# dec14  = load_excel_file('DECEMBER', 'combined_q14.xlsx')\n",
    "# jan14  = load_excel_file('JANUARY',  'combined_q14.xlsx')\n",
    "\n",
    "# # Preview the first few rows and shape of each dataset\n",
    "# def preview_dataset(df, name):\n",
    "#     if df is not None:\n",
    "#         print(f\"\\n{name} Q14 Data Preview:\")\n",
    "#         print(f\"Shape: {df.shape}\")  # (rows, columns)\n",
    "#         print(df.head(2))\n",
    "\n",
    "# preview_dataset(sept14, \"September\")\n",
    "# preview_dataset(oct14,  \"October\")\n",
    "# preview_dataset(nov14,  \"November\")\n",
    "# preview_dataset(dec14,  \"December\")\n",
    "# preview_dataset(jan14,  \"January\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response ID\n",
      "16880    144\n",
      "217      144\n",
      "219      144\n",
      "220      144\n",
      "221      144\n",
      "        ... \n",
      "227      144\n",
      "228      144\n",
      "229      144\n",
      "230      144\n",
      "231      144\n",
      "Name: count, Length: 3494, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count = sept14['Response ID'].value_counts()\n",
    "# print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q15.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q15.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q15.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q15.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q15.xlsx\n",
      "September Q15 Data Preview:\n",
      "   Response ID                                           Platform  \\\n",
      "0          217  Online search (e.g. Google, Bing):LG:AU - And ...   \n",
      "1          217  Online search (e.g. Google, Bing):BOSCH:AU - A...   \n",
      "\n",
      "                    Platform_cleaned  Seen Y/N  Brand  \n",
      "0  Online search (e.g. Google, Bing)         0     LG  \n",
      "1  Online search (e.g. Google, Bing)         0  BOSCH  \n",
      "\n",
      "October Q15 Data Preview:\n",
      "   Response ID                                           Platform  \\\n",
      "0        16909  Online search (e.g. Google, Bing):SAMSUNG:AU -...   \n",
      "1        16909  Online shopping website:SAMSUNG:AU - And on wh...   \n",
      "\n",
      "                    Platform_cleaned  Seen Y/N    Brand  \n",
      "0  Online search (e.g. Google, Bing)         0  SAMSUNG  \n",
      "1            Online shopping website         0  SAMSUNG  \n",
      "\n",
      "November Q15 Data Preview:\n",
      "   Response ID                                           Platform  \\\n",
      "0        48910  None of the above:FISHER&PAYKEL:AU - And on wh...   \n",
      "1        48910  Price comparison site:WESTINGHOUSE:AU - And on...   \n",
      "\n",
      "        Platform_cleaned  Seen Y/N          Brand  \n",
      "0      None of the above         0  FISHER&PAYKEL  \n",
      "1  Price comparison site         0   WESTINGHOUSE  \n",
      "\n",
      "December Q15 Data Preview:\n",
      "   Response ID                                           Platform  \\\n",
      "0        78230  Online search (e.g. Google, Bing):BOSCH:GM - A...   \n",
      "1        78230  None of the above:ROWENTA:GM - And on which of...   \n",
      "\n",
      "                    Platform_cleaned  Seen Y/N    Brand  \n",
      "0  Online search (e.g. Google, Bing)         0    BOSCH  \n",
      "1                  None of the above         0  ROWENTA  \n",
      "\n",
      "January Q15 Data Preview:\n",
      "   Response ID                                           Platform  \\\n",
      "0          219  Online shopping website:DYSON:UK - And on whic...   \n",
      "1          219  None of the above:DYSON:UK - And on which of t...   \n",
      "\n",
      "          Platform_cleaned  Seen Y/N  Brand  \n",
      "0  Online shopping website         0  DYSON  \n",
      "1        None of the above         0  DYSON  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# sept15 = load_excel_file('SEPTEMBER', 'combined_q15.xlsx')\n",
    "# oct15 = load_excel_file('OCTOBER', 'combined_q15.xlsx')\n",
    "# nov15 = load_excel_file('NOVEMBER', 'combined_q15.xlsx')\n",
    "# dec15 = load_excel_file('DECEMBER', 'combined_q15.xlsx')\n",
    "# jan15 = load_excel_file('JANUARY', 'combined_q15.xlsx')\n",
    "\n",
    "# # Preview the first few rows of both datasets\n",
    "# if sept15 is not None:\n",
    "#     print(\"September Q15 Data Preview:\")\n",
    "#     print(sept15.head(2))\n",
    "\n",
    "# if oct15 is not None:\n",
    "#     print(\"\\nOctober Q15 Data Preview:\")\n",
    "#     print(oct15.head(2))\n",
    "\n",
    "# if nov15 is not None:\n",
    "#     print(\"\\nNovember Q15 Data Preview:\")\n",
    "#     print(nov15.head(2))\n",
    "\n",
    "# if dec15 is not None:\n",
    "#     print(\"\\nDecember Q15 Data Preview:\")\n",
    "#     print(dec15.head(2))\n",
    "\n",
    "# if jan15 is not None:\n",
    "#     print(\"\\nJanuary Q15 Data Preview:\")\n",
    "#     print(jan15.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q16.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q16.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q16.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q16.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q16.xlsx\n",
      "September Q16 Data Preview:\n",
      "   Response ID                                       SCM_Platform  \\\n",
      "0          217  Instagram content:FISHER&PAYKEL:AU - And which...   \n",
      "1          217  Live streaming:HAIER:AU - And which of these t...   \n",
      "\n",
      "  SCM_Platform_cleaned  Y/N          Brand  \n",
      "0    Instagram content    1  FISHER&PAYKEL  \n",
      "1       Live streaming    0          HAIER  \n",
      "\n",
      "October Q16 Data Preview:\n",
      "   Response ID                                       SCM_Platform  \\\n",
      "0        16909  Live streaming:MIELE:AU - And which of these t...   \n",
      "1        16909  Tik Tok content:DYSON:AU - And which of these ...   \n",
      "\n",
      "  SCM_Platform_cleaned  Y/N  Brand  \n",
      "0       Live streaming    0  MIELE  \n",
      "1      Tik Tok content    0  DYSON  \n",
      "\n",
      "November Q16 Data Preview:\n",
      "   Response ID                                       SCM_Platform  \\\n",
      "0        48910  Live streaming:SMEG:AU - And which of these ty...   \n",
      "1        48910  Instagram content:DYSON:AU - And which of thes...   \n",
      "\n",
      "  SCM_Platform_cleaned  Y/N  Brand  \n",
      "0       Live streaming    0   SMEG  \n",
      "1    Instagram content    0  DYSON  \n",
      "\n",
      "December Q16 Data Preview:\n",
      "   Response ID                                       SCM_Platform  \\\n",
      "0        78230  Live streaming:BOSCH:GM - And which of these t...   \n",
      "1        78230  Collaboration with Influencer:AEG:GM - And whi...   \n",
      "\n",
      "            SCM_Platform_cleaned  Y/N  Brand  \n",
      "0                 Live streaming    0  BOSCH  \n",
      "1  Collaboration with Influencer    0    AEG  \n",
      "\n",
      "January Q16 Data Preview:\n",
      "   Response ID                                       SCM_Platform  \\\n",
      "0          219  Live streaming:LG:UK - And which of these type...   \n",
      "1          219  Forums (user groups, Facebook groups, etc.):HO...   \n",
      "\n",
      "                          SCM_Platform_cleaned  Y/N     Brand  \n",
      "0                               Live streaming    0        LG  \n",
      "1  Forums (user groups, Facebook groups, etc.)    0  HOTPOINT  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# sept16 = load_excel_file('SEPTEMBER', 'combined_q16.xlsx')\n",
    "# oct16 = load_excel_file('OCTOBER', 'combined_q16.xlsx')\n",
    "# nov16 = load_excel_file('NOVEMBER', 'combined_q16.xlsx')\n",
    "# dec16 = load_excel_file('DECEMBER', 'combined_q16.xlsx')\n",
    "# jan16 = load_excel_file('JANUARY', 'combined_q16.xlsx')\n",
    "\n",
    "\n",
    "# # Preview the first few rows of both datasets\n",
    "# if sept16 is not None:\n",
    "#     print(\"September Q16 Data Preview:\")\n",
    "#     print(sept16.head(2))\n",
    "\n",
    "# if oct16 is not None:\n",
    "#     print(\"\\nOctober Q16 Data Preview:\")\n",
    "#     print(oct16.head(2))\n",
    "\n",
    "# if nov16 is not None:\n",
    "#     print(\"\\nNovember Q16 Data Preview:\")\n",
    "#     print(nov16.head(2))\n",
    "\n",
    "# if dec16 is not None:\n",
    "#     print(\"\\nDecember Q16 Data Preview:\")\n",
    "#     print(dec16.head(2))\n",
    "\n",
    "# if jan16 is not None:\n",
    "#     print(\"\\nJanuary Q16 Data Preview:\")\n",
    "#     print(jan16.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q17.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q17.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q17.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q17.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q17.xlsx\n",
      "\n",
      "September Q17 Data Preview:\n",
      "Shape: (277288, 5)\n",
      "   Response ID                                     Offline_source  \\\n",
      "0          217  Large Roadside Posters/ billboards:SAMSUNG:AU ...   \n",
      "1          217  Large Roadside Posters/ billboards:WESTINGHOUS...   \n",
      "\n",
      "               Offline_source_cleaned  Y/N         Brand  \n",
      "0  Large Roadside Posters/ billboards    0       SAMSUNG  \n",
      "1  Large Roadside Posters/ billboards    0  WESTINGHOUSE  \n",
      "\n",
      "October Q17 Data Preview:\n",
      "Shape: (294560, 5)\n",
      "   Response ID                                     Offline_source  \\\n",
      "0        16909  On transport (eg bus-sides and taxis):HISENSE:...   \n",
      "1        16909  At events (eg concerts  / festivals):AEG:AU - ...   \n",
      "\n",
      "                  Offline_source_cleaned  Y/N    Brand  \n",
      "0  On transport (eg bus-sides and taxis)    0  HISENSE  \n",
      "1   At events (eg concerts  / festivals)    0      AEG  \n",
      "\n",
      "November Q17 Data Preview:\n",
      "Shape: (296315, 5)\n",
      "   Response ID                                     Offline_source  \\\n",
      "0        48910  On transport (eg bus-sides and taxis):BOSCH:AU...   \n",
      "1        48910  At sports stadiums (e.g. on the perimeter boar...   \n",
      "\n",
      "                              Offline_source_cleaned  Y/N  Brand  \n",
      "0              On transport (eg bus-sides and taxis)    0  BOSCH  \n",
      "1  At sports stadiums (e.g. on the perimeter boards)    0  MIELE  \n",
      "\n",
      "December Q17 Data Preview:\n",
      "Shape: (291879, 5)\n",
      "   Response ID                                     Offline_source  \\\n",
      "0        78230  Large Roadside Posters/ billboards:BOSCH:GM - ...   \n",
      "1        78230  Large Roadside Posters/ billboards:ROWENTA:GM ...   \n",
      "\n",
      "               Offline_source_cleaned  Y/N    Brand  \n",
      "0  Large Roadside Posters/ billboards    0    BOSCH  \n",
      "1  Large Roadside Posters/ billboards    0  ROWENTA  \n",
      "\n",
      "January Q17 Data Preview:\n",
      "Shape: (302232, 5)\n",
      "   Response ID                                     Offline_source  \\\n",
      "0          219  Large Roadside Posters/ billboards:LG:UK -  An...   \n",
      "1          219  At events (eg concerts Â / festivals):HOTPOINT...   \n",
      "\n",
      "                  Offline_source_cleaned  Y/N     Brand  \n",
      "0     Large Roadside Posters/ billboards    0        LG  \n",
      "1  At events (eg concerts Â / festivals)    0  HOTPOINT  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# # Load the datasets\n",
    "# sept17 = load_excel_file('SEPTEMBER', 'combined_q17.xlsx')\n",
    "# oct17  = load_excel_file('OCTOBER',  'combined_q17.xlsx')\n",
    "# nov17  = load_excel_file('NOVEMBER', 'combined_q17.xlsx')\n",
    "# dec17  = load_excel_file('DECEMBER', 'combined_q17.xlsx')\n",
    "# jan17  = load_excel_file('JANUARY',  'combined_q17.xlsx')\n",
    "\n",
    "# # Preview the first few rows and shape of each dataset\n",
    "# def preview_dataset(df, name):\n",
    "#     if df is not None:\n",
    "#         print(f\"\\n{name} Q17 Data Preview:\")\n",
    "#         print(f\"Shape: {df.shape}\")  # (rows, columns)\n",
    "#         print(df.head(2))\n",
    "\n",
    "# preview_dataset(sept17, \"September\")\n",
    "# preview_dataset(oct17,  \"October\")\n",
    "# preview_dataset(nov17,  \"November\")\n",
    "# preview_dataset(dec17,  \"December\")\n",
    "# preview_dataset(jan17,  \"January\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q18.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q18.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q18.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q18.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q18.xlsx\n",
      "September Q18 Data Preview:\n",
      "   Response ID                                   Product_Category  \\\n",
      "0          217  Hob:LG:AU - Which product categories from each...   \n",
      "1          217  Refrigerator:SAMSUNG:AU - Which product catego...   \n",
      "\n",
      "  Product_Category_cleaned  Seen or Heard Y/N    Brand Experience_Area  \n",
      "0                      Hob                  0       LG           Taste  \n",
      "1             Refrigerator                  0  SAMSUNG           Taste  \n",
      "\n",
      "October Q18 Data Preview:\n",
      "   Response ID                                   Product_Category  \\\n",
      "0        16909  Hob:DYSON:AU - Which product categories from e...   \n",
      "1        16909  Air Purifier:DYSON:AU - Which product categori...   \n",
      "\n",
      "  Product_Category_cleaned  Seen or Heard Y/N  Brand  Experience_Area  \n",
      "0                      Hob                  0  DYSON            Taste  \n",
      "1             Air Purifier                  0  DYSON  Wellbeing & SDA  \n",
      "\n",
      "November Q18 Data Preview:\n",
      "   Response ID                                   Product_Category  \\\n",
      "0        48910  Vacuum Cleaners:ELECTROLUX:AU - Which product ...   \n",
      "1        48910  Tumble Dryers:WESTINGHOUSE:AU - Which product ...   \n",
      "\n",
      "  Product_Category_cleaned  Seen or Heard Y/N         Brand  Experience_Area  \n",
      "0          Vacuum Cleaners                  1    ELECTROLUX  Wellbeing & SDA  \n",
      "1            Tumble Dryers                  0  WESTINGHOUSE             Care  \n",
      "\n",
      "December Q18 Data Preview:\n",
      "   Response ID                                   Product_Category  \\\n",
      "0        78230  Oven:SIEMENS:GM - Which product categories fro...   \n",
      "1        78230  None of these:PHILIPS:GM - Which product categ...   \n",
      "\n",
      "  Product_Category_cleaned  Seen or Heard Y/N    Brand Experience_Area  \n",
      "0                     Oven                  0  SIEMENS           Taste  \n",
      "1            None of these                  0  PHILIPS           Other  \n",
      "\n",
      "January Q18 Data Preview:\n",
      "   Response ID                                   Product_Category  \\\n",
      "0          219  Air Purifier:SAMSUNG:UK - Which product catego...   \n",
      "1          219  Cooker:AEG:UK - Which product categories from ...   \n",
      "\n",
      "  Product_Category_cleaned  Seen or Heard Y/N    Brand  Experience_Area  \n",
      "0             Air Purifier                  0  SAMSUNG  Wellbeing & SDA  \n",
      "1                   Cooker                  1      AEG            Taste  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# sept18 = load_excel_file('SEPTEMBER', 'combined_q18.xlsx')\n",
    "# oct18 = load_excel_file('OCTOBER', 'combined_q18.xlsx')\n",
    "# nov18 = load_excel_file('NOVEMBER', 'combined_q18.xlsx')\n",
    "# dec18 = load_excel_file('DECEMBER', 'combined_q18.xlsx')\n",
    "# jan18 = load_excel_file('JANUARY', 'combined_q18.xlsx')\n",
    "\n",
    "# # Preview the first few rows of both datasets\n",
    "# if sept18 is not None:\n",
    "#     print(\"September Q18 Data Preview:\")\n",
    "#     print(sept18.head(2))\n",
    "\n",
    "# if oct18 is not None:\n",
    "#     print(\"\\nOctober Q18 Data Preview:\")\n",
    "#     print(oct18.head(2))\n",
    "\n",
    "# if nov18 is not None:\n",
    "#     print(\"\\nNovember Q18 Data Preview:\")\n",
    "#     print(nov18.head(2))\n",
    "\n",
    "# if dec18 is not None:\n",
    "#     print(\"\\nDecember Q18 Data Preview:\")\n",
    "#     print(dec18.head(2))\n",
    "\n",
    "# if jan18 is not None:\n",
    "#     print(\"\\nJanuary Q18 Data Preview:\")\n",
    "#     print(jan18.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q19.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q19.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q19.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q19.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q19.xlsx\n",
      "\n",
      "September Q19 Data Preview:\n",
      "Shape: (71140, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0          244  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1          245  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  Bought_last12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                    NaN  \n",
      "1  A built-in fridge or fridge / freezer                    NaN  \n",
      "\n",
      "October Q19 Data Preview:\n",
      "Shape: (73128, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        16972  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        17045  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  Bought_last12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                      0  \n",
      "1  A built-in fridge or fridge / freezer                      0  \n",
      "\n",
      "November Q19 Data Preview:\n",
      "Shape: (73620, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        48912  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        48913  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  Bought_last12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                      0  \n",
      "1  A built-in fridge or fridge / freezer                      0  \n",
      "\n",
      "December Q19 Data Preview:\n",
      "Shape: (72860, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        78230  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        78263  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  Bought_last12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                      0  \n",
      "1  A built-in fridge or fridge / freezer                      0  \n",
      "\n",
      "January Q19 Data Preview:\n",
      "Shape: (73152, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        96209  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        96211  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  Bought_last12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                      0  \n",
      "1  A built-in fridge or fridge / freezer                      0  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# # Load the datasets\n",
    "# sept19 = load_excel_file('SEPTEMBER', 'combined_q19.xlsx')\n",
    "# oct19  = load_excel_file('OCTOBER',  'combined_q19.xlsx')\n",
    "# nov19  = load_excel_file('NOVEMBER', 'combined_q19.xlsx')\n",
    "# dec19  = load_excel_file('DECEMBER', 'combined_q19.xlsx')\n",
    "# jan19  = load_excel_file('JANUARY',  'combined_q19.xlsx')\n",
    "\n",
    "# # Preview the first few rows and shape of each dataset\n",
    "# def preview_dataset(df, name):\n",
    "#     if df is not None:\n",
    "#         print(f\"\\n{name} Q19 Data Preview:\")\n",
    "#         print(f\"Shape: {df.shape}\")  # (rows, columns)\n",
    "#         print(df.head(2))\n",
    "\n",
    "# preview_dataset(sept19, \"September\")\n",
    "# preview_dataset(oct19,  \"October\")\n",
    "# preview_dataset(nov19,  \"November\")\n",
    "# preview_dataset(dec19,  \"December\")\n",
    "# preview_dataset(jan19,  \"January\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\SEPTEMBER\\combined_q20.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\OCTOBER\\combined_q20.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\NOVEMBER\\combined_q20.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\DECEMBER\\combined_q20.xlsx\n",
      "Loading data from: C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\JANUARY\\combined_q20.xlsx\n",
      "\n",
      "September Q20 Data Preview:\n",
      "Shape: (71140, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0          244  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1          245  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  IntendtoBuy_next12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                           0  \n",
      "1  A built-in fridge or fridge / freezer                           1  \n",
      "\n",
      "October Q20 Data Preview:\n",
      "Shape: (73128, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        16972  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        17045  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  IntendtoBuy_next12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                           0  \n",
      "1  A built-in fridge or fridge / freezer                           0  \n",
      "\n",
      "November Q20 Data Preview:\n",
      "Shape: (73620, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        48912  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        48913  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  IntendtoBuy_next12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                           1  \n",
      "1  A built-in fridge or fridge / freezer                           0  \n",
      "\n",
      "December Q20 Data Preview:\n",
      "Shape: (72860, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        78230  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        78263  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  IntendtoBuy_next12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                           0  \n",
      "1  A built-in fridge or fridge / freezer                           0  \n",
      "\n",
      "January Q20 Data Preview:\n",
      "Shape: (73152, 4)\n",
      "   Response ID                                         Appliances  \\\n",
      "0        96209  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "1        96211  A built-in fridge or fridge / freezer:GM - Whi...   \n",
      "\n",
      "                      Appliances_cleaned  IntendtoBuy_next12Mths Y/N  \n",
      "0  A built-in fridge or fridge / freezer                           1  \n",
      "1  A built-in fridge or fridge / freezer                           0  \n"
     ]
    }
   ],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# # Load the datasets\n",
    "# sept20 = load_excel_file('SEPTEMBER', 'combined_q20.xlsx')\n",
    "# oct20 = load_excel_file('OCTOBER', 'combined_q20.xlsx')\n",
    "# nov20 = load_excel_file('NOVEMBER', 'combined_q20.xlsx')\n",
    "# dec20 = load_excel_file('DECEMBER', 'combined_q20.xlsx')\n",
    "# jan20 = load_excel_file('JANUARY', 'combined_q20.xlsx')\n",
    "\n",
    "# # Preview the first few rows and shape of each dataset\n",
    "# def preview_dataset(df, name):\n",
    "#     if df is not None:\n",
    "#         print(f\"\\n{name} Q20 Data Preview:\")\n",
    "#         print(f\"Shape: {df.shape}\")  # (rows, columns)\n",
    "#         print(df.head(2))\n",
    "\n",
    "# preview_dataset(sept20, \"September\")\n",
    "# preview_dataset(oct20, \"October\")\n",
    "# preview_dataset(nov20, \"November\")\n",
    "# preview_dataset(dec20, \"December\")\n",
    "# preview_dataset(jan20, \"January\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# sept20 = load_excel_file('SEPTEMBER', 'combined_q20.xlsx')\n",
    "# oct20 = load_excel_file('OCTOBER', 'combined_q20.xlsx')\n",
    "# nov20 = load_excel_file('NOVEMBER', 'combined_q20.xlsx')\n",
    "# dec20 = load_excel_file('DECEMBER', 'combined_q20.xlsx')\n",
    "# jan20 = load_excel_file('JANUARY', 'combined_q20.xlsx')\n",
    "\n",
    "# # Preview the first few rows of both datasets\n",
    "# if sept20 is not None:\n",
    "#     print(\"September Q20 Data Preview:\")\n",
    "#     print(sept20.head(2))\n",
    "\n",
    "# if oct20 is not None:\n",
    "#     print(\"\\nOctober Q20 Data Preview:\")\n",
    "#     print(oct20.head(2))\n",
    "\n",
    "# if nov20 is not None:\n",
    "#     print(\"\\nNovember Q20 Data Preview:\")\n",
    "#     print(nov20.head(2))\n",
    "\n",
    "# if dec20 is not None:\n",
    "#     print(\"\\nDecember Q20 Data Preview:\")\n",
    "#     print(dec20.head(2))\n",
    "\n",
    "# if jan20 is not None:\n",
    "#     print(\"\\nJanuary Q20 Data Preview:\")\n",
    "#     print(jan20.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Helper function to load Excel files\n",
    "# def load_excel_file(subfolder, filename):\n",
    "#     file_path = os.path.join(base_dir, subfolder, filename)\n",
    "#     try:\n",
    "#         print(f\"Loading data from: {file_path}\")\n",
    "#         return pd.read_excel(file_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Error: File not found at {file_path}\")\n",
    "#         return None\n",
    "\n",
    "# sept_userprofile = load_excel_file('SEPTEMBER', 'combined_user_profile.xlsx')\n",
    "# oct_userprofile = load_excel_file('OCTOBER', 'combined_user_profile.xlsx')\n",
    "# nov_userprofile = load_excel_file('NOVEMBER', 'combined_user_profile.xlsx')\n",
    "# dec_userprofile = load_excel_file('DECEMBER', 'combined_user_profile.xlsx')\n",
    "\n",
    "# # Preview the first few rows of both datasets\n",
    "# if sept_userprofile is not None:\n",
    "#     print(\"September User Profile Data Preview:\")\n",
    "#     print(sept_userprofile.head(2))\n",
    "\n",
    "# if oct_userprofile is not None:\n",
    "#     print(\"\\nOctober User Profile Data Preview:\")\n",
    "#     print(oct_userprofile.head(2))\n",
    "\n",
    "# if nov_userprofile is not None:\n",
    "#     print(\"\\nNovember User Profile Data Preview:\")\n",
    "#     print(nov_userprofile.head(2))\n",
    "\n",
    "# if dec_userprofile is not None:\n",
    "#     print(\"\\nDecember User Profile Data Preview:\")\n",
    "#     print(dec_userprofile.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concat file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 214356 entries, 0 to 214355\n",
      "Data columns (total 3 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   Response ID  214356 non-null  int64 \n",
      " 1   Brand        214356 non-null  object\n",
      " 2   Aware Y/N    214356 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_13 = pd.concat([sept13, oct13, nov13, dec13, jan13], ignore_index=True)\n",
    "\n",
    "# combined_13.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q13.csv', float_format='%.0f', index=False)\n",
    "# combined_13.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2576224 entries, 0 to 2576223\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Dtype \n",
      "---  ------           ----- \n",
      " 0   Response ID      int64 \n",
      " 1   Source           object\n",
      " 2   cleaned_source   object\n",
      " 3   Brand_awareness  int64 \n",
      " 4   Brand            object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 98.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_14 = pd.concat([sept14, oct14, nov14, dec14, jan14], ignore_index=True)\n",
    "\n",
    "# combined_14.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q14.csv', float_format='%.0f', index=False)\n",
    "# combined_14.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_source\n",
      "Not seen/heard                                                            214752\n",
      "Newspaper/Magazine (advertisements)                                       214752\n",
      "YouTube / Video                                                           214752\n",
      "From a friend, family or someone else I know                              214752\n",
      "At Events (fairs & exhibitions, sports, cooking, etc.)                    214752\n",
      "When searching or shopping online                                         214752\n",
      "In a store                                                                214752\n",
      "Outdoors (e.g. poster, bus stop, LCD/screen, underground, street lamp)    214752\n",
      "On TV (live, catch up or on demand)                                       214752\n",
      "Social media, e.g. Facebook and/or Instagram                              214752\n",
      "Somewhere else                                                            213952\n",
      "On a brand’s own website, app or e-mail                                   153636\n",
      "On a brandâ€™s own website, app or e-mail                                  61116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(combined_14['cleaned_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_source\n",
      "Not seen/heard                                                            214752\n",
      "Newspaper/Magazine (advertisements)                                       214752\n",
      "YouTube / Video                                                           214752\n",
      "From a friend, family or someone else I know                              214752\n",
      "At Events (fairs & exhibitions, sports, cooking, etc.)                    214752\n",
      "When searching or shopping online                                         214752\n",
      "In a store                                                                214752\n",
      "Outdoors (e.g. poster, bus stop, LCD/screen, underground, street lamp)    214752\n",
      "On TV (live, catch up or on demand)                                       214752\n",
      "Social media, e.g. Facebook and/or Instagram                              214752\n",
      "Somewhere else                                                            213952\n",
      "On a brand’s own website, app or e-mail                                   153636\n",
      "On a brandâ€™s own website, app or e-mail                                  61116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Normalize column names by replacing curly quotes with straight quotes\n",
    "# combined_14.columns = combined_14.columns.str.replace('’', \"'\", regex=False)\n",
    "# combined_14.columns = combined_14.columns.str.replace('‘', \"'\", regex=False)\n",
    "\n",
    "# # Now rename the column\n",
    "# combined_14 = combined_14.rename(columns={\n",
    "#     \"On a brand's own website, app or e-mail\": \"On a brand's own website, app or e-mail\"\n",
    "# })\n",
    "\n",
    "# print(combined_14['cleaned_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalize column names by replacing curly quotes with straight quotes\n",
    "# combined_14.columns = combined_14.columns.str.replace('’', \"'\", regex=False)\n",
    "# combined_14.columns = combined_14.columns.str.replace('‘', \"'\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize the 'cleaned_source' column values\n",
    "# combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('’', \"'\", regex=False)\n",
    "# combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('‘', \"'\", regex=False)\n",
    "# combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('â€™', \"'\", regex=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_source\n",
      "Not seen/heard                                                            214752\n",
      "Newspaper/Magazine (advertisements)                                       214752\n",
      "YouTube / Video                                                           214752\n",
      "On a brand's own website, app or e-mail                                   214752\n",
      "On TV (live, catch up or on demand)                                       214752\n",
      "At Events (fairs & exhibitions, sports, cooking, etc.)                    214752\n",
      "From a friend, family or someone else I know                              214752\n",
      "Outdoors (e.g. poster, bus stop, LCD/screen, underground, street lamp)    214752\n",
      "In a store                                                                214752\n",
      "When searching or shopping online                                         214752\n",
      "Social media, e.g. Facebook and/or Instagram                              214752\n",
      "Somewhere else                                                            213952\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# # Check for duplicates in the 'cleaned_source' column\n",
    "# print(combined_14['cleaned_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_14.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q14.csv', float_format='%.0f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1044511 entries, 0 to 1044510\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count    Dtype \n",
      "---  ------            --------------    ----- \n",
      " 0   Response ID       1044511 non-null  int64 \n",
      " 1   Platform          1044511 non-null  object\n",
      " 2   Platform_cleaned  1044511 non-null  object\n",
      " 3   Seen Y/N          1044511 non-null  int64 \n",
      " 4   Brand             1044511 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 39.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_15 = pd.concat([sept15, oct15, nov15, dec15, jan15], ignore_index=True)\n",
    "\n",
    "# combined_15.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q15.csv', float_format='%.0f', index=False)\n",
    "# combined_15.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1483423 entries, 0 to 1483422\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count    Dtype \n",
      "---  ------                --------------    ----- \n",
      " 0   Response ID           1483423 non-null  int64 \n",
      " 1   SCM_Platform          1483423 non-null  object\n",
      " 2   SCM_Platform_cleaned  1483423 non-null  object\n",
      " 3   Y/N                   1483423 non-null  int64 \n",
      " 4   Brand                 1483423 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 56.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_16 = pd.concat([sept16, oct16, nov16, dec16, jan16], ignore_index=True)\n",
    "\n",
    "# combined_16.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q16.csv', float_format='%.0f', index=False)\n",
    "# combined_16.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1462274 entries, 0 to 1462273\n",
      "Data columns (total 5 columns):\n",
      " #   Column                  Non-Null Count    Dtype \n",
      "---  ------                  --------------    ----- \n",
      " 0   Response ID             1462274 non-null  int64 \n",
      " 1   Offline_source          1462274 non-null  object\n",
      " 2   Offline_source_cleaned  1462274 non-null  object\n",
      " 3   Y/N                     1462274 non-null  int64 \n",
      " 4   Brand                   1462274 non-null  object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 55.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_17 = pd.concat([sept17, oct17, nov17, dec17, jan17], ignore_index=True)\n",
    "\n",
    "# combined_17.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q17.csv', float_format='%.0f', index=False)\n",
    "# combined_17.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3004556 entries, 0 to 3004555\n",
      "Data columns (total 6 columns):\n",
      " #   Column                    Dtype \n",
      "---  ------                    ----- \n",
      " 0   Response ID               int64 \n",
      " 1   Product_Category          object\n",
      " 2   Product_Category_cleaned  object\n",
      " 3   Seen or Heard Y/N         int64 \n",
      " 4   Brand                     object\n",
      " 5   Experience_Area           object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 137.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_18 = pd.concat([sept18, oct18, nov18, dec18, jan18], ignore_index=True)\n",
    "\n",
    "# combined_18.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q18.csv', float_format='%.0f', index=False)\n",
    "# combined_18.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363900 entries, 0 to 363899\n",
      "Data columns (total 4 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   Response ID            363900 non-null  int64  \n",
      " 1   Appliances             363900 non-null  object \n",
      " 2   Appliances_cleaned     363900 non-null  object \n",
      " 3   Bought_last12Mths Y/N  301239 non-null  float64\n",
      "dtypes: float64(1), int64(1), object(2)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_19 = pd.concat([sept19, oct19, nov19, dec19, jan19], ignore_index=True)\n",
    "\n",
    "# combined_19.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q19.csv', float_format='%.0f', index=False)\n",
    "# combined_19.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 363900 entries, 0 to 363899\n",
      "Data columns (total 4 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   Response ID                 363900 non-null  int64 \n",
      " 1   Appliances                  363900 non-null  object\n",
      " 2   Appliances_cleaned          363900 non-null  object\n",
      " 3   IntendtoBuy_next12Mths Y/N  363900 non-null  int64 \n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 11.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_20 = pd.concat([sept20, oct20, nov20, dec20, jan20], ignore_index=True)\n",
    "\n",
    "# combined_20.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT24-JAN25\\merged_jan_Q20.csv', float_format='%.0f', index=False)\n",
    "# combined_20.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7091 entries, 0 to 7090\n",
      "Data columns (total 38 columns):\n",
      " #   Column                                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                --------------  -----  \n",
      " 0   Response ID                                                                                                                           7091 non-null   int64  \n",
      " 1   Date Submitted                                                                                                                        7091 non-null   object \n",
      " 2   Status                                                                                                                                7091 non-null   object \n",
      " 3   IP Address                                                                                                                            7091 non-null   object \n",
      " 4   Longitude                                                                                                                             7091 non-null   int64  \n",
      " 5   Latitude                                                                                                                              7091 non-null   int64  \n",
      " 6   Country                                                                                                                               7091 non-null   object \n",
      " 7   City                                                                                                                                  5972 non-null   object \n",
      " 8   State/Region                                                                                                                          6024 non-null   object \n",
      " 9   Postal                                                                                                                                5218 non-null   object \n",
      " 10  URL Variable: bcid                                                                                                                    3488 non-null   object \n",
      " 11  URL Variable: brid                                                                                                                    3488 non-null   object \n",
      " 12  URL Variable: country                                                                                                                 3494 non-null   object \n",
      " 13  URL Variable: language                                                                                                                3494 non-null   object \n",
      " 14  language                                                                                                                              7091 non-null   int64  \n",
      " 15  BRID                                                                                                                                  7079 non-null   object \n",
      " 16  BCID                                                                                                                                  7079 non-null   object \n",
      " 17  TEST MODE (ON/OFF)                                                                                                                    7091 non-null   object \n",
      " 18  Termination page                                                                                                                      7091 non-null   object \n",
      " 19  Month                                                                                                                                 7091 non-null   int64  \n",
      " 20  Week                                                                                                                                  7091 non-null   int64  \n",
      " 21  Home construction or remodeling:Do you or does any member of your household work in any of these occupations? Select all that apply.  413 non-null    float64\n",
      " 22  Financial Services:Do you or does any member of your household work in any of these occupations? Select all that apply.               341 non-null    float64\n",
      " 23  None of these:Do you or does any member of your household work in any of these occupations? Select all that apply.                    6380 non-null   float64\n",
      " 24  New Hidden Value                                                                                                                      7091 non-null   object \n",
      " 25  Copy of New Hidden Value                                                                                                              7091 non-null   object \n",
      " 26  Which country are you currently residing in?                                                                                          7091 non-null   int64  \n",
      " 27  Which_region/city_do_you_live_in?                                                                                                     3494 non-null   object \n",
      " 28  Which_of_the_following_best_describes_the_area_in_which_you_live?                                                                     7091 non-null   object \n",
      " 29  Gender                                                                                                                                7091 non-null   object \n",
      " 30  Age                                                                                                                                   7091 non-null   int64  \n",
      " 31  Age_Range                                                                                                                             3494 non-null   object \n",
      " 32  Range_household_income                                                                                                                7012 non-null   object \n",
      " 33  highest level of education you have completed?                                                                                        7091 non-null   object \n",
      " 34  best applies to the home you live in?                                                                                                 7091 non-null   object \n",
      " 35  Decision maker                                                                                                                        7091 non-null   object \n",
      " 36  Region                                                                                                                                3597 non-null   object \n",
      " 37  Age Range                                                                                                                             3597 non-null   object \n",
      "dtypes: float64(3), int64(8), object(27)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# combined_septoct_user_profile = pd.concat([sept_userprofile, oct_userprofile], ignore_index=True)\n",
    "\n",
    "# combined_septoct_user_profile.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-OCT\\merged_sept_oct_user_profile.csv', float_format='%.0f', index=False)\n",
    "\n",
    "# combined_septoct_user_profile.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************** Q14, q18,need some major rechecking ************ q15, q20 *********"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x80 in position 1037: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the CSV file and display its info\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mUsers\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43maisar\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mOneDrive\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mDocuments\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mELECTROLUX\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mPROCESSED-DATA\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mCOMBINED\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mSEPT-DEC\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mmerged_sept_dec_user_profile.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\u001b[39;00m\n\u001b[0;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python313\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m<frozen codecs>:325\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(self, input, final)\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x80 in position 1037: invalid start byte"
     ]
    }
   ],
   "source": [
    "# # df = pd.read_csv('merged_sept_dec_user_profile.csv')\n",
    "\n",
    "# # df = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\merged_sept_dec_user_profile.csv')\n",
    "# # df.info()\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file and display its info\n",
    "# # df = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_sept_dec_user_profile.csv')\n",
    "# # C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\n",
    "# df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14298 entries, 0 to 14297\n",
      "Data columns (total 32 columns):\n",
      " #   Column                                                                                                                                Non-Null Count  Dtype  \n",
      "---  ------                                                                                                                                --------------  -----  \n",
      " 0   Response ID                                                                                                                           14298 non-null  int64  \n",
      " 1   Date Submitted                                                                                                                        14298 non-null  object \n",
      " 2   Status                                                                                                                                14298 non-null  object \n",
      " 3   IP Address                                                                                                                            14298 non-null  object \n",
      " 4   Longitude                                                                                                                             14297 non-null  float64\n",
      " 5   Latitude                                                                                                                              14297 non-null  float64\n",
      " 6   Country                                                                                                                               14297 non-null  object \n",
      " 7   City                                                                                                                                  12006 non-null  object \n",
      " 8   State/Region                                                                                                                          12106 non-null  object \n",
      " 9   Postal                                                                                                                                10454 non-null  object \n",
      " 10  language                                                                                                                              14298 non-null  int64  \n",
      " 11  BRID                                                                                                                                  14286 non-null  object \n",
      " 12  BCID                                                                                                                                  14286 non-null  object \n",
      " 13  TEST MODE (ON/OFF)                                                                                                                    14298 non-null  object \n",
      " 14  Termination page                                                                                                                      14298 non-null  object \n",
      " 15  Month                                                                                                                                 14298 non-null  int64  \n",
      " 16  Week                                                                                                                                  14298 non-null  int64  \n",
      " 17  Home construction or remodeling:Do you or does any member of your household work in any of these occupations? Select all that apply.  851 non-null    float64\n",
      " 18  Financial Services:Do you or does any member of your household work in any of these occupations? Select all that apply.               692 non-null    float64\n",
      " 19  None of these:Do you or does any member of your household work in any of these occupations? Select all that apply.                    12833 non-null  float64\n",
      " 20  New Hidden Value                                                                                                                      14298 non-null  object \n",
      " 21  Copy of New Hidden Value                                                                                                              14298 non-null  object \n",
      " 22  Which country are you currently residing in?                                                                                          14298 non-null  int64  \n",
      " 23  Region                                                                                                                                14298 non-null  object \n",
      " 24  Which_of_the_following_best_describes_the_area_in_which_you_live?                                                                     14298 non-null  object \n",
      " 25  Gender                                                                                                                                14298 non-null  object \n",
      " 26  Age                                                                                                                                   14298 non-null  int64  \n",
      " 27  Age_Range                                                                                                                             14298 non-null  object \n",
      " 28  Range_household_income                                                                                                                14116 non-null  object \n",
      " 29  highest level of education you have completed?                                                                                        14298 non-null  object \n",
      " 30  best applies to the home you live in?                                                                                                 14298 non-null  object \n",
      " 31  Decision maker                                                                                                                        14298 non-null  object \n",
      "dtypes: float64(5), int64(6), object(21)\n",
      "memory usage: 3.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# # Load the CSV file using an alternative encoding\n",
    "# file_path = r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_sept_dec_user_profile.csv'\n",
    "\n",
    "# try:\n",
    "#     df = pd.read_csv(file_path, encoding='latin1')  # Common fallback encoding\n",
    "#     df.info()\n",
    "# except UnicodeDecodeError:\n",
    "#     print(\"Unable to decode file. Please verify the file encoding.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Response ID', 'Date Submitted', 'Status', 'IP Address', 'Longitude',\n",
       "       'Latitude', 'Country', 'City', 'State/Region', 'Postal', 'language',\n",
       "       'BRID', 'BCID', 'TEST MODE (ON/OFF)', 'Termination page', 'Month',\n",
       "       'Week',\n",
       "       'Home construction or remodeling:Do you or does any member of your household work in any of these occupations? Select all that apply.',\n",
       "       'Financial Services:Do you or does any member of your household work in any of these occupations? Select all that apply.',\n",
       "       'None of these:Do you or does any member of your household work in any of these occupations? Select all that apply.',\n",
       "       'New Hidden Value', 'Copy of New Hidden Value',\n",
       "       'Which country are you currently residing in?', 'Region',\n",
       "       'Which_of_the_following_best_describes_the_area_in_which_you_live?',\n",
       "       'Gender', 'Age', 'Age_Range', 'Range_household_income',\n",
       "       'highest level of education you have completed?',\n",
       "       'best applies to the home you live in?', 'Decision maker'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Range_household_income\n",
      "THB 30,001 - 50,000          553\n",
      " 30,000 -  44,999          518\n",
      "AUD 2,000 - 4,000            436\n",
      "VND 10,500,001-15,000,000    429\n",
      "VND 15,000,001-20,000,000    409\n",
      "                            ... \n",
      "160 000 CHF - 179 999 CHF     25\n",
      "Less than THB 15,000          25\n",
      "200 000 CHF - 219 999 CHF     24\n",
      "180 000 CHF - 199 999 CHF     23\n",
      "up to 999 z?                  20\n",
      "Name: count, Length: 86, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# print(df['Range_household_income'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Special Case for January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df13 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q13.xlsx')\n",
    "df14 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q14.xlsx')\n",
    "df15 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q15.xlsx')\n",
    "df16 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q16.xlsx')\n",
    "df17 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q17.xlsx')\n",
    "df18 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q18.xlsx')\n",
    "df19 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q19.xlsx')\n",
    "df20 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q20.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df14 = pd.read_excel(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\2025\\FEBRUARY\\combined_q14.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq13 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q13.csv')\n",
    "dq14 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q14.csv')\n",
    "dq15 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q15.csv')\n",
    "dq16 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q16.csv')\n",
    "dq17 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q17.csv')\n",
    "dq18 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q18.csv')\n",
    "dq19 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q19.csv')\n",
    "dq20 = pd.read_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\SEPT-DEC\\merged_jan_Q20.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dq13: (171180, 3), df13: (43176, 3)\n",
      "dq14: (2058112, 5), df14: (518112, 5)\n",
      "dq15: (828631, 5), df15: (215880, 5)\n",
      "dq16: (1181191, 5), df16: (302232, 5)\n",
      "dq17: (1160042, 5), df17: (299432, 5)\n",
      "dq18: (2400092, 6), df18: (604464, 6)\n",
      "dq19: (290748, 4), df19: (73152, 4)\n",
      "dq20: (290748, 4), df20: (73152, 4)\n"
     ]
    }
   ],
   "source": [
    "print(f'dq13: {dq13.shape}, df13: {df13.shape}')\n",
    "print(f'dq14: {dq14.shape}, df14: {df14.shape}')\n",
    "print(f'dq15: {dq15.shape}, df15: {df15.shape}')\n",
    "print(f'dq16: {dq16.shape}, df16: {df16.shape}')\n",
    "print(f'dq17: {dq17.shape}, df17: {df17.shape}')\n",
    "print(f'dq18: {dq18.shape}, df18: {df18.shape}')\n",
    "print(f'dq19: {dq19.shape}, df19: {df19.shape}')\n",
    "print(f'dq20: {dq20.shape}, df20: {df20.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(214356, 3)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_13 = pd.concat([dq13, df13], ignore_index=True)\n",
    "\n",
    "combined_13.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q13.csv', float_format='%.0f', index=False)\n",
    "combined_13.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2576224, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_14 = pd.concat([dq14, df14], ignore_index=True)\n",
    "\n",
    "combined_14.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q14.csv', float_format='%.0f', index=False)\n",
    "combined_14.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_source\n",
      "Not seen/heard                                                            214752\n",
      "Newspaper/Magazine (advertisements)                                       214752\n",
      "YouTube / Video                                                           214752\n",
      "At Events (fairs & exhibitions, sports, cooking, etc.)                    214752\n",
      "Outdoors (e.g. poster, bus stop, LCD/screen, underground, street lamp)    214752\n",
      "From a friend, family or someone else I know                              214752\n",
      "In a store                                                                214752\n",
      "Social media, e.g. Facebook and/or Instagram                              214752\n",
      "On TV (live, catch up or on demand)                                       214752\n",
      "When searching or shopping online                                         214752\n",
      "Somewhere else                                                            213952\n",
      "On a brand’s own website, app or e-mail                                   153636\n",
      "On a brand's own website, app or e-mail                                    41928\n",
      "On a brandâ€™s own website, app or e-mail                                  19188\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(combined_14['cleaned_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaned_source\n",
      "Not seen/heard                                                            214752\n",
      "Newspaper/Magazine (advertisements)                                       214752\n",
      "YouTube / Video                                                           214752\n",
      "On a brand's own website, app or e-mail                                   214752\n",
      "On TV (live, catch up or on demand)                                       214752\n",
      "At Events (fairs & exhibitions, sports, cooking, etc.)                    214752\n",
      "From a friend, family or someone else I know                              214752\n",
      "Outdoors (e.g. poster, bus stop, LCD/screen, underground, street lamp)    214752\n",
      "In a store                                                                214752\n",
      "When searching or shopping online                                         214752\n",
      "Social media, e.g. Facebook and/or Instagram                              214752\n",
      "Somewhere else                                                            213952\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('’', \"'\", regex=False)\n",
    "combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('‘', \"'\", regex=False)\n",
    "combined_14['cleaned_source'] = combined_14['cleaned_source'].str.replace('â€™', \"'\", regex=False)\n",
    "\n",
    "print(combined_14['cleaned_source'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_14.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q14.csv', float_format='%.0f', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1044511, 5)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_15 = pd.concat([dq15, df15], ignore_index=True)\n",
    "\n",
    "combined_15.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q15.csv', float_format='%.0f', index=False)\n",
    "combined_15.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1483423, 5)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_16 = pd.concat([dq16, df16], ignore_index=True)\n",
    "\n",
    "combined_16.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q16.csv', float_format='%.0f', index=False)\n",
    "combined_16.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1459474, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_17 = pd.concat([dq17, df17], ignore_index=True)\n",
    "\n",
    "combined_17.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q17.csv', float_format='%.0f', index=False)\n",
    "combined_17.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3004556, 6)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_18 = pd.concat([dq18, df18], ignore_index=True)\n",
    "\n",
    "combined_18.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q18.csv', float_format='%.0f', index=False)\n",
    "combined_18.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363900, 4)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_19 = pd.concat([dq19, df19], ignore_index=True)\n",
    "\n",
    "combined_19.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q19.csv', float_format='%.0f', index=False)\n",
    "combined_19.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363900, 4)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_20 = pd.concat([dq20, df20], ignore_index=True)\n",
    "\n",
    "combined_20.to_csv(r'C:\\Users\\aisar\\OneDrive\\Documents\\ELECTROLUX\\PROCESSED-DATA\\COMBINED\\temp\\merged_jan_q20.csv', float_format='%.0f', index=False)\n",
    "combined_20.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
